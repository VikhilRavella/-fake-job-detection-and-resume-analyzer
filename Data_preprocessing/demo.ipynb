{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "237b2f20",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "/home/vikhil/miniconda3/envs/vikhil/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so: undefined symbol: iJIT_NotifyEvent",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch version:\u001b[39m\u001b[38;5;124m\"\u001b[39m, torch\u001b[38;5;241m.\u001b[39m__version__)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA version:\u001b[39m\u001b[38;5;124m\"\u001b[39m, torch\u001b[38;5;241m.\u001b[39mversion\u001b[38;5;241m.\u001b[39mcuda)\n",
      "File \u001b[0;32m~/miniconda3/envs/vikhil/lib/python3.10/site-packages/torch/__init__.py:367\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m USE_GLOBAL_DEPS:\n\u001b[1;32m    366\u001b[0m         _load_global_deps()\n\u001b[0;32m--> 367\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_C\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mSymInt\u001b[39;00m:\n\u001b[1;32m    371\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;124;03m    Like an int (including magic methods), but redirects all operations on the\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;124;03m    wrapped node. This is used in particular to symbolically record operations\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;124;03m    in the symbolic shape workflow.\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: /home/vikhil/miniconda3/envs/vikhil/lib/python3.10/site-packages/torch/lib/libtorch_cpu.so: undefined symbol: iJIT_NotifyEvent"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"CUDA version:\", torch.version.cuda)\n",
    "print(\"cuDNN version:\", torch.backends.cudnn.version())\n",
    "print(\"Is CUDA available?:\", torch.cuda.is_available())\n",
    "print(\"Device count:\", torch.cuda.device_count())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Current device:\", torch.cuda.current_device())\n",
    "    print(\"Device name:\", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93775cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "#from torchtext.data.utils import get_tokenizer\n",
    "#from torchtext.vocab import build_vocab_from_iterator\n",
    "#from torch.nn.utils.rnn import pad_sequence\n",
    "import torch\n",
    "import nltk\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "from torchtext.transforms import BasicEnglishNormalize, Tokenizer\n",
    "\n",
    "# Example tokenizer\n",
    "from torchtext.data.utils import get_tokenizer  # For older versions use below\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "class GPUTextPreprocessor:\n",
    "    def __init__(self, texts, device='cuda', perform_spell_correction=False):\n",
    "        self.device = device if torch.cuda.is_available() else 'cpu'\n",
    "        self.tokenizer = get_tokenizer(\"basic_english\")\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.perform_spell_correction = perform_spell_correction\n",
    "        \n",
    "        if self.perform_spell_correction:\n",
    "            from spellchecker import SpellChecker\n",
    "            self.spell = SpellChecker()\n",
    "\n",
    "        self.cleaned_texts = [self.clean_text(t) for t in texts]\n",
    "        def token_iterator():\n",
    "            for text in self.cleaned_texts:\n",
    "                yield self.tokenizer(text)\n",
    "        self.vocab = build_vocab_from_iterator(token_iterator(), specials=[\"<unk>\"])\n",
    "        self.vocab.set_default_index(self.vocab[\"<unk>\"])\n",
    "\n",
    "    def clean_text(self, text):\n",
    "        if pd.isna(text): return \"\"\n",
    "        text = BeautifulSoup(text, \"html.parser\").get_text()\n",
    "        text = text.lower().translate(str.maketrans('', '', string.punctuation))\n",
    "        tokens = [t for t in self.tokenizer(text) if t not in self.stop_words and t.isalpha()]\n",
    "        if self.perform_spell_correction:\n",
    "            tokens = [self.spell.correction(t) for t in tokens]\n",
    "        tokens = [self.lemmatizer.lemmatize(t) for t in tokens]\n",
    "        return ' '.join(tokens)\n",
    "\n",
    "    def encode_tensor(self, cleaned_text):\n",
    "        tokens = self.tokenizer(cleaned_text)\n",
    "        indices = [self.vocab[token] for token in tokens]\n",
    "        return torch.tensor(indices, dtype=torch.long).to(self.device)\n",
    "\n",
    "    def batch_encode(self):\n",
    "        tensors = [self.encode_tensor(t) for t in self.cleaned_texts if t]\n",
    "        if not tensors: return torch.tensor([]).to(self.device)\n",
    "        return pad_sequence(tensors, batch_first=True, padding_value=self.vocab[\"<unk>\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
